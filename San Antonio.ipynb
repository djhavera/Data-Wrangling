{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area\n",
    "\n",
    "San Antonio, TX United States\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/san-antonio_texas/\n",
    "\n",
    "This map is of San Antonio, the city where my grandparents lived and where I spent the holidays growing up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems Encountered in the Map\n",
    "\n",
    "I noticed one main problem with the data: \n",
    "\n",
    "Numerous abbreviations for street names ('North US Highway 281','US Highway 281','United States Highway 281')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"san-antonio_texas.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 1 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set\n",
    "We can see from the count tags function the amount of nodes, members, tags, and ways below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 23537,\n",
       " 'nd': 1479783,\n",
       " 'node': 1244193,\n",
       " 'osm': 1,\n",
       " 'relation': 1718,\n",
       " 'tag': 751039,\n",
       " 'way': 144603}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "\n",
    "    return tags\n",
    "\n",
    "count_tags(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if re.search(lower,k):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.search(lower_colon,k):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars,k):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "        return keys\n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 432074, 'lower_colon': 310783, 'other': 8182, 'problemchars': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "OSMFILE = \"example.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Interstate Highway\", \"Farm-to-Market\" ]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ste\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Hwy\": \"Interstate Highway\",\n",
    "            \"Hiwy\": \"Interstate Highway\",\n",
    "            \"IH\": \"Interstate Highway\",\n",
    "            \"I-\": \"Interstate Highway\",\n",
    "            \"I-H\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\", \n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"FM\": \"Farm-to-Market\",\n",
    "            \"Plz\": \"plaza\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'100': {'S Interstate 35 Ste 100', 'W Ave #100'},\n",
       "             '101': {'Dolorosa St #101'},\n",
       "             '102': {'North Loop 1604 East, Suite 102'},\n",
       "             '103': {'Broadway St #103', 'Stone Oak Pkwy #103'},\n",
       "             '105': {'SE Military Drive Ste 105'},\n",
       "             '109': {'Huebner Rd #109'},\n",
       "             '1101': {'FM 1101'},\n",
       "             '111': {'W Loop 1604 N Ste 111'},\n",
       "             '112': {'US Hwy 281 North, Suite 112'},\n",
       "             '117': {'La Cantera Parkway Ste 117'},\n",
       "             '12': {'Old Ranch Road 12', 'RM 12', 'Ranch Road 12'},\n",
       "             '123': {'Business 123',\n",
       "              'S State Hwy 123',\n",
       "              'S. Hiwy 123',\n",
       "              'South State Highway 123',\n",
       "              'State Highway 123',\n",
       "              'TX 123'},\n",
       "             '1283': {'FM 1283'},\n",
       "             '131': {'Fredericksburg Rd #131'},\n",
       "             '132': {'State Highway 132'},\n",
       "             '1346': {'FM 1346', 'Farm-to-Market Road 1346'},\n",
       "             '151': {'State Highway 151'},\n",
       "             '1516': {'Farm-to-Market Road 1516'},\n",
       "             '16': {'Highway 16', 'State Highway 16'},\n",
       "             '1604': {'Loop 1604'},\n",
       "             '2': {'Nacogdoches Rd Bldg 2'},\n",
       "             '2011': {'Huebner Rd #2011'},\n",
       "             '209': {'North Loop 1604 W, Suite 209'},\n",
       "             '21': {'Airport Highway 21'},\n",
       "             '251': {'Fourwinds Dr. #251'},\n",
       "             '2538': {'FM 2538'},\n",
       "             '281': {'North US Highway 281',\n",
       "              'US Highway 281',\n",
       "              'United States Highway 281'},\n",
       "             '306': {'12454 FM 306', 'FM 306'},\n",
       "             '3159': {'Farm-to-Market Road 3159'},\n",
       "             '325': {'SW Military Drive Ste 325'},\n",
       "             '3351': {'FM 3351', 'Farm-to-Market Road 3351'},\n",
       "             '337': {'Loop 337', 'State Loop 337'},\n",
       "             '35': {'N Business Loop IH 35',\n",
       "              'North IH 35',\n",
       "              'North Interstate Highway 35',\n",
       "              'South Interstate 35',\n",
       "              'South Interstate Highway 35'},\n",
       "             '381': {'County Road 381'},\n",
       "             '410': {'Northeast Loop 410',\n",
       "              'Northwest Loop 410',\n",
       "              'Southeast Loop 410',\n",
       "              'Southwest Loop 410'},\n",
       "             '420': {'NW Loop 420'},\n",
       "             '46': {'North State Highway 46',\n",
       "              'South State Highway 46',\n",
       "              'State Highway 46',\n",
       "              'TX 46',\n",
       "              'West State Highway 46'},\n",
       "             '464': {'FM 464'},\n",
       "             '477': {'FM 477'},\n",
       "             '482': {'FM 482'},\n",
       "             '540': {'E. Basse Road Bldg B #540'},\n",
       "             '725': {'Farm-to-Market Road 725'},\n",
       "             '775': {'FM 775'},\n",
       "             '78': {'FM 78', 'Farm-to-Market Road 78'},\n",
       "             '87': {'US 87'},\n",
       "             '90': {'Alternate 90'},\n",
       "             '900': {'San Pedro Ave Ste 900'},\n",
       "             'A': {'Avenue A', 'Medical Parkway #A'},\n",
       "             'Alder': {'Mountain Alder'},\n",
       "             'Audrey': {'Ashton Audrey'},\n",
       "             'Ave': {'San Pedro Ave'},\n",
       "             'Avenida': {'Cresta Avenida'},\n",
       "             'B': {'Avenue B'},\n",
       "             'Bay': {'Bourdeaux Bay', 'Goldenrain Bay'},\n",
       "             'Bend': {'Brisbane Bend',\n",
       "              'Broadmoor Bend',\n",
       "              'Fishers Bend',\n",
       "              'Kallison Bend',\n",
       "              'Magnolia Bend',\n",
       "              'Spicewood Bend',\n",
       "              'Stonewall Bend',\n",
       "              'Woodland Bend',\n",
       "              'Woodway Bend'},\n",
       "             'Bluff': {'River Bluff'},\n",
       "             'Blvd': {'Randolph Blvd'},\n",
       "             'Bois': {'Clos Du Bois'},\n",
       "             'Bonham': {'Bonham'},\n",
       "             'Braesview': {'Braesview'},\n",
       "             'Broadway': {'Broadway'},\n",
       "             'Bypass': {'550 N Hwy 123 Bypass',\n",
       "              'North Highway 123 Bypass',\n",
       "              'South Highway 123 Bypass'},\n",
       "             'C': {'Avenue C'},\n",
       "             'Cakebread': {'Cakebread'},\n",
       "             'Cantera': {'Via La Cantera'},\n",
       "             'Casbury': {'Casbury'},\n",
       "             'Cedar': {'Gray Cedar'},\n",
       "             'Circle': {'Auditorium Circle',\n",
       "              'Bear Tree Circle',\n",
       "              'Carlson Circle',\n",
       "              'Cooper Circle',\n",
       "              'Forum Circle',\n",
       "              'Llano Circle',\n",
       "              'Lookout Hollow Circle',\n",
       "              'Main Circle',\n",
       "              'Susan Circle'},\n",
       "             'Coach': {'Dunhill Coach'},\n",
       "             'Cogburn': {'Cogburn'},\n",
       "             'Corral': {'Cooper Corral'},\n",
       "             'Cove': {'Country Cove',\n",
       "              'Dream Cove',\n",
       "              'Keystone Cove',\n",
       "              'Oakview Cove',\n",
       "              'Rustling Cove',\n",
       "              'Seal Cove'},\n",
       "             'Creek': {'Buck Creek',\n",
       "              'Cinnamon Creek',\n",
       "              'Cloudy Creek',\n",
       "              'Cougar Creek',\n",
       "              'Curres Creek',\n",
       "              'Daylight Creek',\n",
       "              'Emerald Creek',\n",
       "              'Flint Creek',\n",
       "              'Kiowa Creek',\n",
       "              'Knoll Creek',\n",
       "              'Low Creek',\n",
       "              'Perrin Creek',\n",
       "              'Pipers Creek',\n",
       "              'Shuman Creek',\n",
       "              'Silent Creek',\n",
       "              'Stormy Creek',\n",
       "              'Taos Creek',\n",
       "              'Treaty Creek',\n",
       "              'Treble Creek',\n",
       "              'Wayside Creek',\n",
       "              'White Creek'},\n",
       "             'Creeks': {'Two Creeks'},\n",
       "             'Crest': {'Daylight Crest', 'Magnolia Crest'},\n",
       "             'Crossing': {'Bowens Crossing',\n",
       "              'Creekside Crossing',\n",
       "              'Zuehl Crossing'},\n",
       "             'D': {'Avenue D', 'NW Loop 410, Ste D'},\n",
       "             'Datapoint': {'Datapoint'},\n",
       "             'Dawn': {'April Dawn', 'Enchanted Dawn', 'Su VIno Dawn'},\n",
       "             'Depot': {'Midway Depot'},\n",
       "             'Dolorosa': {'Dolorosa'},\n",
       "             'Dr': {'LBJ Dr', 'N LBJ Dr', 'Sea World Dr', 'Town Center Dr'},\n",
       "             'Dugas': {'Dugas'},\n",
       "             'E': {'Avenue E', 'N Loop 1604 E'},\n",
       "             'East': {'Interstate 10 East',\n",
       "              'Interstate Highway 10 East',\n",
       "              'North Loop 1604 East',\n",
       "              'South Loop 1604 East'},\n",
       "             'End': {'Coves End'},\n",
       "             'FM1376': {'FM1376'},\n",
       "             'Falls': {'Alomosa Falls', 'Elise Falls'},\n",
       "             'Field': {'Magnolia Field', 'Royal Field'},\n",
       "             'Fountainwood': {'Fountainwood'},\n",
       "             'Freeway': {'McDermott Freeway'},\n",
       "             'Frontage': {'I-35 Frontage', 'South I-35 Frontage'},\n",
       "             'G': {'Avenue G'},\n",
       "             'Gap': {'Drew Gap'},\n",
       "             'Gardendale': {'Gardendale'},\n",
       "             'Gate': {'Balcones Gate'},\n",
       "             'Glade': {'Misty Glade', 'Pebble Glade'},\n",
       "             'Green': {'Bulverde Green', 'Hunters Green'},\n",
       "             'Grove': {'Red Grove'},\n",
       "             'H10C': {'NW Loop 410 Space H10C'},\n",
       "             'Highway': {'Austin Highway',\n",
       "              'Northwest Military Highway',\n",
       "              'Stockdale Highway'},\n",
       "             'Hill': {'Cavern Hill',\n",
       "              'Chalk Hill',\n",
       "              'Cinnamon Hill',\n",
       "              'Driftwood Hill',\n",
       "              'Magnolia Hill',\n",
       "              'Windsor Hill'},\n",
       "             'Home': {'Sutter Home'},\n",
       "             'I-35': {'I-35'},\n",
       "             'IH-35': {'IH-35'},\n",
       "             'Inglenook': {'Inglenook'},\n",
       "             'Italia': {'Piazza Italia'},\n",
       "             'Knoll': {'Amber Knoll', 'North Knoll'},\n",
       "             'Krug': {'Daniel Krug'},\n",
       "             'Land': {'Royal Land'},\n",
       "             'Landing': {'City Base Landing'},\n",
       "             'Larkspur': {'Larkspur'},\n",
       "             'Leap': {'Frogs Leap', 'Stags Leap'},\n",
       "             'Loop': {'Anderson Loop',\n",
       "              'Corridor Loop',\n",
       "              'Grand Loop',\n",
       "              'Westwood Loop'},\n",
       "             'MCILVAINE': {'MCILVAINE'},\n",
       "             'Marina': {'Marina'},\n",
       "             'Martinelli': {'Martinelli'},\n",
       "             \"Mary's\": {\"North Saint Mary's\"},\n",
       "             'Meadow': {'Klein Meadow'},\n",
       "             'Mesa': {'Osage Mesa'},\n",
       "             'Mill': {'Border Mill', 'Cooper Mill', 'Rockwall Mill'},\n",
       "             'Minter': {'Merton Minter'},\n",
       "             'Mist': {'Emerald Mist', 'Magnolia Mist', 'Vineyard Mist'},\n",
       "             'Mondavi': {'Robert Mondavi'},\n",
       "             'Moon': {'Brazos Moon', 'Sycamore Moon'},\n",
       "             'Mossrock': {'Mossrock'},\n",
       "             'Norte': {'Vista del Norte'},\n",
       "             'North': {'East Loop 1604 North',\n",
       "              'I-35 North',\n",
       "              'I-H 35 North',\n",
       "              'IH 35 North',\n",
       "              'Interstate Highway 35 North',\n",
       "              'State Highway 46 North',\n",
       "              'West Loop 1604 North'},\n",
       "             'Oak': {'Burtons Oak',\n",
       "              'Gathering Oak',\n",
       "              'Haven Oak',\n",
       "              'Laurel Oak',\n",
       "              'Monterrey Oak',\n",
       "              'Painted Oak',\n",
       "              'Soaring Oak',\n",
       "              'Terra Oak',\n",
       "              'Wilderness Oak'},\n",
       "             'Oaks': {'Alto Oaks',\n",
       "              'Ancient Oaks',\n",
       "              'Bay Oaks',\n",
       "              'Crescent Oaks',\n",
       "              'Cypress Oaks',\n",
       "              'Echoing Oaks',\n",
       "              'Huebner Oaks',\n",
       "              'Jalane Oaks',\n",
       "              'Laurel Oaks',\n",
       "              'Paseo Oaks',\n",
       "              'Winston Oaks'},\n",
       "             'Paige': {'Erin Paige'},\n",
       "             'Palm': {'Windmill Palm'},\n",
       "             'Park': {'Enero Park',\n",
       "              'Grace Park',\n",
       "              'Jalane Park',\n",
       "              'Mancero Park',\n",
       "              'Newoak Park',\n",
       "              'Sutters Park',\n",
       "              'Treeline Park',\n",
       "              'Woodrose Park'},\n",
       "             'Parkford': {'Parkford'},\n",
       "             'Pass': {'Barrel Pass',\n",
       "              'Cooper Pass',\n",
       "              'Dakota Pass',\n",
       "              'Grapevine Pass',\n",
       "              'Henderson Pass',\n",
       "              'Heritage Pass',\n",
       "              'Limestone Pass',\n",
       "              'Paisano Pass',\n",
       "              'Rim Pass',\n",
       "              'Walnut Pass',\n",
       "              'Woodland Pass'},\n",
       "             'Path': {'Mulberry Path', 'Timber Path', 'Wine Rose Path'},\n",
       "             'Peak': {'Buffalo Peak',\n",
       "              'Eagle Peak',\n",
       "              'Geyser Peak',\n",
       "              'Palo Duro Peak'},\n",
       "             'Pedroncelli': {'Pedroncelli'},\n",
       "             'Phelps': {'Joseph Phelps'},\n",
       "             'Pkwy': {'La Cantera Pkwy'},\n",
       "             'Plaza': {'Alamo Plaza', 'Military Plaza'},\n",
       "             'Plz': {'Main Plz'},\n",
       "             'Point': {'Cibolo Point',\n",
       "              'Cougar Point',\n",
       "              'Elwell Point',\n",
       "              'Leighs Point',\n",
       "              'Palomino Point',\n",
       "              'Wolf Point'},\n",
       "             'Pointe': {'Azalea Pointe', 'Silver Pointe'},\n",
       "             'Post': {'Trading Post'},\n",
       "             'Prima': {'Avenida Prima'},\n",
       "             'Quail': {'Silver Quail'},\n",
       "             'Rafanelli': {'Rafanelli'},\n",
       "             'Rainbow': {'Sunset Rainbow'},\n",
       "             'Ranch': {'Briggs Ranch',\n",
       "              'Cimarron Ranch',\n",
       "              'Reid Ranch',\n",
       "              'River Ranch',\n",
       "              'Shavano Ranch',\n",
       "              'Starr Ranch',\n",
       "              'Stephens Ranch',\n",
       "              'Swayback Ranch'},\n",
       "             'Rd': {'137 Old San Antonio Rd',\n",
       "              'Eisenhauer Rd',\n",
       "              'I-10 Frontage Rd'},\n",
       "             'Reagan': {'Ronald Reagan'},\n",
       "             'Rhapsody': {'West Rhapsody'},\n",
       "             'Rialto': {'Calle Rialto'},\n",
       "             'Ridge': {'Alameda Ridge',\n",
       "              'Chestnut Ridge',\n",
       "              'Cinema Ridge',\n",
       "              'Cougar Ridge',\n",
       "              'Cypress Ridge',\n",
       "              'Daylight Ridge',\n",
       "              'Dover Ridge',\n",
       "              'Encanto Ridge',\n",
       "              'Overlook Ridge',\n",
       "              'Rainbow Ridge',\n",
       "              'Raven Ridge',\n",
       "              'Rocky Ridge',\n",
       "              'Stormy Ridge',\n",
       "              'Talavera Ridge',\n",
       "              'Thomas Ridge'},\n",
       "             'Ridgebrook': {'Ridgebrook'},\n",
       "             'Rio': {'Encino Rio'},\n",
       "             'Rise': {'Redstone Rise'},\n",
       "             'River': {'Magnolia River'},\n",
       "             'Rock': {'Painted Rock',\n",
       "              'Scenic Rock',\n",
       "              'Silver Rock',\n",
       "              'Stormy Rock'},\n",
       "             'Rosemoss': {'Rosemoss'},\n",
       "             'Rousseau': {'Rousseau'},\n",
       "             'Route': {'Cimarron Route'},\n",
       "             'Row': {'Produce Row', 'University Row'},\n",
       "             'Run': {'Collenback Run',\n",
       "              'Daisy Run',\n",
       "              'Ledge Run',\n",
       "              'Magnolia Run',\n",
       "              'Piney Wood Run',\n",
       "              'Shelbys Run',\n",
       "              'Wild Horse Run'},\n",
       "             'S': {'Interstate 35 S'},\n",
       "             'Saintsbury': {'Saintsbury'},\n",
       "             'Sandau': {'Sandau'},\n",
       "             'Seascape': {'Seascape'},\n",
       "             'Shadow': {'Oak Shadow'},\n",
       "             'Sonoma': {'Lake Sonoma', 'Piper Sonoma'},\n",
       "             'South': {'IH 35 South',\n",
       "              'Interstate Highway 37 South',\n",
       "              'State Highway 16 South'},\n",
       "             'Spot': {'Silver Spot'},\n",
       "             'Springs': {'Blanco Springs',\n",
       "              'Coral Springs',\n",
       "              'Flora Springs',\n",
       "              'Menger Springs'},\n",
       "             'Spruce': {'Silver Spruce'},\n",
       "             'St': {'E Locust St',\n",
       "              'North Guadalupe St',\n",
       "              'W Commerce St',\n",
       "              'W Josephine St',\n",
       "              'W Martin St'},\n",
       "             'Stage': {'Baywater Stage',\n",
       "              'Brazos Stage',\n",
       "              'Calvary Stage',\n",
       "              'Chilton Stage',\n",
       "              'Midnight Stage'},\n",
       "             'Star': {'Mountain Star'},\n",
       "             'Summit': {'Magnolia Summit'},\n",
       "             'Sunrise': {'Silent Sunrise'},\n",
       "             'Sunset': {'Pecos Sunset'},\n",
       "             'TX-46': {'TX-46'},\n",
       "             'Terrace': {'Ascend Terrace',\n",
       "              'Autumn Terrace',\n",
       "              'Green Terrace',\n",
       "              'Justin Terrace',\n",
       "              'La Cantera Terrace',\n",
       "              'Sage Terrace'},\n",
       "             'Tilson': {'Tilson'},\n",
       "             'Top': {'Mountain Top'},\n",
       "             'Trace': {'River Trace', 'Woodland Trace'},\n",
       "             'Trafalgar': {'Trafalgar'},\n",
       "             'Train': {'Wagon Train'},\n",
       "             'Trolley': {'Golden Trolley'},\n",
       "             'Vail': {'Summer Vail'},\n",
       "             'Valet': {'Vista Valet'},\n",
       "             'Valley': {'Cooper Valley', 'Sun Valley'},\n",
       "             'View': {'Cap Rock View',\n",
       "              'Chappel View',\n",
       "              'MacArthur View',\n",
       "              'Oak Top View'},\n",
       "             'Vista': {'Dillons Vista'},\n",
       "             'Way': {'Camp Light Way',\n",
       "              'Cottonwood Way',\n",
       "              'Creekside Way',\n",
       "              'Johnson Way',\n",
       "              'Kings Way',\n",
       "              'Klein Way',\n",
       "              'Larco Way',\n",
       "              'Marlinton Way',\n",
       "              'Parkwood Way',\n",
       "              'Rialto Way',\n",
       "              'Technology Way',\n",
       "              'Valero Way',\n",
       "              'Wagon Wheel Way',\n",
       "              'Willmon Way',\n",
       "              'Wormack Way'},\n",
       "             'West': {'IH-10 West',\n",
       "              'Interstate Highway 10 West',\n",
       "              'Military Drive West',\n",
       "              'North Loop 1604 West',\n",
       "              'State Highway 46 West'},\n",
       "             'Wetz': {'Wetz'},\n",
       "             'Wheel': {'Wagon Wheel'},\n",
       "             'Willow': {'Brandon Willow'},\n",
       "             'Woodchase': {'Woodchase'},\n",
       "             'Woodlake': {'Fm 78 Ste Woodlake'},\n",
       "             'Woods': {'Blanco Woods', 'Corporate Woods'},\n",
       "             'Wurzbach': {'Harry Wurzbach'}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() not in expected:\n",
    "        if m.group() in mapping.keys():\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for attribute in element.attrib:\n",
    "            if attribute in NODE_FIELDS:\n",
    "                node_attribs[attribute]=element.attrib[attribute]\n",
    "        \n",
    "        sub_iter=element.iter(\"tag\")\n",
    "        for atr in sub_iter:\n",
    "            k_val=atr.attrib['k']\n",
    "            locol=LOWER_COLON.search(k_val)\n",
    "            prochar=PROBLEMCHARS.search(k_val)\n",
    "            if locol:\n",
    "                key_list = k_val.split(':',1)\n",
    "                k_key=key_list[1]\n",
    "                tag_type=key_list[0]\n",
    "            elif prochar:\n",
    "                break\n",
    "            else:\n",
    "                tag_type=\"regular\"\n",
    "                k_key=k_val\n",
    "            v_val=atr.attrib['v']\n",
    "            content={\"id\":node_attribs['id'],'key':k_key,'value':v_val,'type':tag_type}\n",
    "            tags.append(content)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for attribute in element.attrib:\n",
    "            if attribute in WAY_FIELDS:\n",
    "                way_attribs[attribute]=element.attrib[attribute]\n",
    "    \n",
    "        sub_iter=element.iter(\"nd\")\n",
    "        level=0\n",
    "        for atr in sub_iter:\n",
    "            for sub_attrib in atr.attrib:\n",
    "                if sub_attrib=='ref':\n",
    "                    content= {\"id\":way_attribs['id'],'node_id':atr.attrib[sub_attrib],'position':level}\n",
    "                    way_nodes.append(content)\n",
    "                    level+=1\n",
    "        sub_iter=element.iter(\"tag\")\n",
    "        for atr in sub_iter:\n",
    "            k_val=atr.attrib['k']\n",
    "            locol=LOWER_COLON.search(k_val)\n",
    "            prochar=PROBLEMCHARS.search(k_val)\n",
    "            if locol:\n",
    "                key_list = k_val.split(':',1)\n",
    "                k_key=key_list[1]\n",
    "                tag_type=key_list[0]\n",
    "            elif prochar:\n",
    "                break\n",
    "            else:\n",
    "                tag_type=\"regular\"\n",
    "                k_key=k_val\n",
    "            v_val=atr.attrib['v']\n",
    "            content={\"id\":way_attribs['id'],'key':k_key,'value':v_val,'type':tag_type}\n",
    "            tags.append(content)            \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add nodes_tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite_file = 'sql_db.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a cursor object\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT,type TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ways_tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways_tags(id INTEGER, key TEXT, value TEXT,type TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add ways_nodes table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "X NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "X WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "X WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['node_id'].decode(\"utf-8\"), i['position'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add ways table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"),\n",
    "              i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add nodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE nodes(id INTEGER, lat REAL, lon REAL, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['lat'].decode(\"utf-8\"), i['lon'].decode(\"utf-8\"),\n",
    "              i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"),\n",
    "              i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\203014767\\Documents\\Python\\SQL\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes.csv...............................: 100M \n",
      "nodes_tags.csv..........................: 2M   \n",
      "sample.osm..............................: 268M \n",
      "San Antonio.ipynb.......................: 56K  \n",
      "san-antonio_texas.osm...................: 265M \n",
      "schema.ipynb............................: 3K   \n",
      "schema.py...............................: 2K   \n",
      "schema.pyc..............................: 1K   \n",
      "sql_db.db...............................: 154M \n",
      "Untitled.ipynb..........................: 72B  \n",
      "ways.csv................................: 8M   \n",
      "ways_nodes.csv..........................: 34M  \n",
      "ways_tags.csv...........................: 23M  \n",
      "San Antonio-checkpoint.ipynb............: 53K  \n",
      "schema-checkpoint.ipynb.................: 72B  \n",
      "Untitled-checkpoint.ipynb...............: 72B  \n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "from hurry.filesize import size\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "files_list = []\n",
    "for path, dirs, files in os.walk(dirpath):\n",
    "    files_list.extend([(filename, size(os.path.getsize(os.path.join(path, filename)))) for filename in files])\n",
    "\n",
    "for filename, size in files_list:\n",
    "    print '{:.<40s}: {:5s}'.format(filename,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The queries below show that there are 1,244,193 nodes and 144,603 ways in the SQL table.  These amounts tie to count tag functon that I used prior to importing the data set into the SQL table.  This query is a check to help ensure that we have uploaded all the data from the csv file correctly to the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1244193,)]\n"
     ]
    }
   ],
   "source": [
    "sqlite_file\n",
    "\n",
    "# Connecting to the database file\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "QUERY1 = '''SELECT COUNT(*) \n",
    "FROM nodes'''\n",
    "\n",
    "cur.execute(QUERY1)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144603,)]\n"
     ]
    }
   ],
   "source": [
    "QUERY2 = '''SELECT COUNT(*) \n",
    "FROM ways'''\n",
    "\n",
    "cur.execute(QUERY2)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users is 828."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(828,)]\n"
     ]
    }
   ],
   "source": [
    "QUERY3 = '''SELECT COUNT(DISTINCT(e.uid))\n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e\n",
    "'''\n",
    "\n",
    "cur.execute(QUERY3)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below shows the number of top 10 amenties in the area.  Places of worship, schools, and restaurants round out the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'place_of_worship', 1061), (u'school', 362), (u'restaurant', 231), (u'fast_food', 183), (u'parking_entrance', 120), (u'bench', 94), (u'pharmacy', 78), (u'toilets', 69), (u'fuel', 59), (u'grave_yard', 59)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY4 = '''SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;'''\n",
    "\n",
    "cur.execute(QUERY4)\n",
    "result = cur.fetchall()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that burger restaurants are the most prevalent in San Antonio.  I would have guessed Mexican restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'burger', 34), (u'sandwich', 33), (u'mexican', 16), (u'chicken', 11), (u'pizza', 8), (u'chinese', 4), (u'american', 3), (u'ice_cream', 2), (u'barbecue', 1), (u'breakfast', 1)]\n"
     ]
    }
   ],
   "source": [
    "QUERY5 = '''SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='fast_food') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;'''\n",
    "\n",
    "cur.execute(QUERY5)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the errors on street names, I wanted to see if zip codes also were error prone.  Interestingly there appears to be two records with zip codes from Charlotte, North Carolina.  Additionally, there appears to be a formatting issue where a zip code can either be 5 digits or 10 digits.  Similiar steps to audit and clean this data will be needed that we took with street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'78255', 2170), (u'78155', 1398), (u'78251', 1127), (u'78230', 746), (u'78249', 500), (u'78253', 399), (u'78216', 302), (u'78240', 282), (u'78006', 187), (u'78666', 170), (u'78257', 143), (u'78217', 117), (u'78229', 81), (u'78130', 77), (u'78245', 65), (u'78121', 58), (u'78218', 49), (u'78205', 45), (u'78209', 44), (u'78250', 44), (u'78258', 44), (u'78154', 42), (u'78232', 39), (u'78223', 34), (u'78109', 33), (u'78207', 33), (u'78256', 31), (u'78247', 28), (u'78227', 26), (u'78238', 26), (u'78023', 25), (u'78212', 24), (u'78233', 23), (u'78254', 21), (u'78201', 20), (u'78204', 19), (u'78210', 17), (u'78228', 17), (u'78213', 15), (u'78224', 15), (u'78132', 14), (u'78114', 13), (u'78231', 13), (u'78244', 13), (u'78070', 12), (u'78211', 12), (u'78219', 12), (u'78222', 12), (u'78259', 12), (u'78215', 11), (u'78221', 11), (u'78237', 11), (u'78108', 10), (u'78239', 10), (u'78214', 9), (u'78648', 9), (u'78148', 8), (u'78248', 7), (u'78226', 6), (u'78235', 6), (u'78242', 6), (u'78002', 5), (u'78052', 5), (u'78260', 5), (u'78015', 4), (u'78073', 4), (u'78133', 4), (u'78163', 4), (u'78202', 4), (u'78101', 3), (u'78112', 3), (u'78208', 3), (u'78220', 3), (u'78252', 3), (u'78288', 3), (u'78016', 2), (u'78063', 2), (u'78124', 2), (u'78155-2214', 2), (u'78232-1341', 2), (u'78261', 2), (u'78264', 2), (u'28207', 1), (u'28239', 1), (u'72840', 1), (u'78130-6389', 1), (u'78154-1265', 1), (u'78155-2217', 1), (u'78155-2354', 1), (u'781553', 1), (u'78156', 1), (u'78225', 1), (u'78229-3322', 1), (u'78230-1898', 1), (u'78236', 1), (u'78238-9998', 1), (u'78247-5929', 1), (u'78249-1620', 1), (u'78249-3701', 1), (u'78251-2101', 1), (u'78284', 1), (u'78666-5923', 1), (u'78666-7235', 1), (u'78731', 1), (u'TX 78006', 1)]\n"
     ]
    }
   ],
   "source": [
    "QUERY6 = '''SELECT tags.value, COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags \n",
    "    UNION ALL \n",
    "    SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;'''\n",
    "cur.execute(QUERY6)\n",
    "result = cur.fetchall()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
