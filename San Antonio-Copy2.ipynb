{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area\n",
    "\n",
    "San Antonio, TX United States\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/san-antonio_texas/\n",
    "\n",
    "This map is of San Antonio, the city where my grandparents lived and where I spent the holidays growing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"san-antonio_texas.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 1 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems Encountered in the Map\n",
    "\n",
    "I noticed several problems with the data: \n",
    "\n",
    "Numerous abbreviations for street names ('North US Highway 281','US Highway 281','United States Highway 281')\n",
    "\n",
    "\n",
    "Inconsistent postal codes (“78155”, “78155-2214”)\n",
    "\n",
    "“Incorrect” postal codes (San Antonio area zip codes all begin with “72” however several zip codes were listed for \"282\" which corresponds to Charlotte, NC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I queried the street names by using audit.py to identify problems with the street names.  I iterated over each word in an address and corrected them to a mapping list below using an update_name function:\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ste\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Hwy\": \"Interstate Highway\",\n",
    "            \"Hiwy\": \"Interstate Highway\",\n",
    "            \"IH\": \"Interstate Highway\",\n",
    "            \"I-\": \"Interstate Highway\",\n",
    "            \"I-H\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\", \n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"FM\": \"Farm-to-Market\",\n",
    "            \"Plz\": \"plaza\"\n",
    "            }\n",
    "            \n",
    "            \n",
    "QUERY_ZIP = '''SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags \n",
    "    UNION ALL \n",
    "    SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;'''\n",
    "cur.execute(QUERY_ZIP)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not clean postal codes, but further steps would be to limit postal codes to 5 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Connecting to the database file\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "QUERY4Z = '''SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags \n",
    "    UNION ALL \n",
    "    SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;'''\n",
    "\n",
    "cur.execute(QUERY4Z)\n",
    "result = cur.fetchall()\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three zip codes 78155, 78666, and 78006 in the 10 of zip codes for San Antonio appear to be in suburbs outside the San Antonio \n",
    "1604 loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "QUERY_ZIP2 = '''SELECT tags.value, COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags \n",
    "    UNION ALL \n",
    "    SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC\n",
    "LIMIT 10;'''\n",
    "cur.execute(QUERY_ZIP2)\n",
    "result_zip2 = cur.fetchall()\n",
    "print(result_zip2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set\n",
    "We can see from the count tags function the amount of nodes, members, tags, and ways below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 23537,\n",
       " 'nd': 1479783,\n",
       " 'node': 1244193,\n",
       " 'osm': 1,\n",
       " 'relation': 1718,\n",
       " 'tag': 751039,\n",
       " 'way': 144603}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "\n",
    "    return tags\n",
    "\n",
    "count_tags(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if re.search(lower,k):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.search(lower_colon,k):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars,k):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "        return keys\n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 432074, 'lower_colon': 310783, 'other': 8182, 'problemchars': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "OSMFILE = \"example.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Interstate Highway\", \"Farm-to-Market\" ]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ste\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Hwy\": \"Interstate Highway\",\n",
    "            \"Hiwy\": \"Interstate Highway\",\n",
    "            \"IH\": \"Interstate Highway\",\n",
    "            \"I-\": \"Interstate Highway\",\n",
    "            \"I-H\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\",\n",
    "            \"Interstate\": \"Interstate Highway\", \n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"FM\": \"Farm-to-Market\",\n",
    "            \"Plz\": \"plaza\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() not in expected:\n",
    "        if m.group() in mapping.keys():\n",
    "            print \"BEFORE\"\n",
    "            print name\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "            print \"AFTER\"\n",
    "            print name\n",
    "            \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for attribute in element.attrib:\n",
    "            if attribute in NODE_FIELDS:\n",
    "                node_attribs[attribute]=element.attrib[attribute]\n",
    "        \n",
    "        sub_iter=element.iter(\"tag\")\n",
    "        for atr in sub_iter:\n",
    "            k_val=atr.attrib['k']\n",
    "            locol=LOWER_COLON.search(k_val)\n",
    "            prochar=PROBLEMCHARS.search(k_val)\n",
    "            key_list = k_val.split(':',1)\n",
    "            k_key=key_list[1]\n",
    "            tag_type=key_list[0]\n",
    "            if locol:\n",
    "                                    # use cleaning function:\n",
    "                if v_val == 'addr:street':\n",
    "                    v_val = update_name(k_val, mapping)\n",
    "                                     # otherwise:\n",
    "                else:\n",
    "                    v_val = k_val  \n",
    "            elif prochar:\n",
    "                v_val=k_val\n",
    "                continue\n",
    "            else:\n",
    "                tag_type=\"regular\"\n",
    "                v_val=k_val\n",
    "  \n",
    "            content={\"id\":node_attribs['id'],'key':k_key,'value':v_val,'type':tag_type}\n",
    "            tags.append(content)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for attribute in element.attrib:\n",
    "            if attribute in WAY_FIELDS:\n",
    "                way_attribs[attribute]=element.attrib[attribute]\n",
    "    \n",
    "        sub_iter=element.iter(\"nd\")\n",
    "        level=0\n",
    "        for atr in sub_iter:\n",
    "            for sub_attrib in atr.attrib:\n",
    "                if sub_attrib=='ref':\n",
    "                    content= {\"id\":way_attribs['id'],'node_id':atr.attrib[sub_attrib],'position':level}\n",
    "                    way_nodes.append(content)\n",
    "                    level+=1\n",
    "        sub_iter=element.iter(\"tag\")\n",
    "        for atr in sub_iter:\n",
    "            k_val=atr.attrib['k']\n",
    "            locol=LOWER_COLON.search(k_val)\n",
    "            prochar=PROBLEMCHARS.search(k_val)\n",
    "            key_list = k_val.split(':',1)\n",
    "            k_key=key_list[1]\n",
    "            tag_type=key_list[0]\n",
    "                       \n",
    "            if locol:\n",
    "\n",
    "                    # use cleaning function:\n",
    "                if v_val == 'addr:street':\n",
    "                    v_val = update_name(k_val, mapping)\n",
    "                    # otherwise:\n",
    "                else:\n",
    "                    v_val = k_val  \n",
    "            elif prochar:\n",
    "                v_val=k_val\n",
    "                continue\n",
    "            else:\n",
    "                tag_type=\"regular\"\n",
    "                v_val=k_val\n",
    "\n",
    "            content={\"id\":way_attribs['id'],'key':k_key,'value':v_val,'type':tag_type}\n",
    "            tags.append(content)            \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-2a47bfbbdf23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[1;31m# Note: Validation is ~ 10X slower. For the project consider using a small\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[1;31m# sample of the map when validating.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOSM_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-2a47bfbbdf23>\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(file_in, validate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'node'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'way'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-603db1fc0d01>\u001b[0m in \u001b[0;36mshape_element\u001b[0;34m(element, node_attr_fields, way_attr_fields, problem_chars, default_tag_type)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprochar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPROBLEMCHARS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mkey_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mk_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtag_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlocol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add nodes_tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite_file = 'sql_db.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a cursor object\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT,type TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ways_tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways_tags(id INTEGER, key TEXT, value TEXT,type TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add ways_nodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['node_id'].decode(\"utf-8\"), i['position'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add ways table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"),\n",
    "              i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add nodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    CREATE TABLE nodes(id INTEGER, lat REAL, lon REAL, user TEXT, uid INTEGER, \n",
    "    version INTEGER, changeset INTEGER, timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['lat'].decode(\"utf-8\"), i['lon'].decode(\"utf-8\"),\n",
    "              i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"),\n",
    "              i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes.csv...............................: 100M \n",
      "nodes_tags.csv..........................: 2M   \n",
      "sample.osm..............................: 268M \n",
      "San Antonio-Copy1.ipynb.................: 82K  \n",
      "San Antonio-Copy2.ipynb.................: 57K  \n",
      "San Antonio-Copy3.ipynb.................: 58K  \n",
      "San Antonio.ipynb.......................: 88K  \n",
      "San+Antonio.html........................: 395K \n",
      "San+Antonio.py..........................: 20K  \n",
      "san-antonio_texas.osm...................: 265M \n",
      "schema.ipynb............................: 3K   \n",
      "schema.py...............................: 2K   \n",
      "schema.pyc..............................: 1K   \n",
      "sql_db.db...............................: 156M \n",
      "Untitled.ipynb..........................: 72B  \n",
      "ways.csv................................: 8M   \n",
      "ways_nodes.csv..........................: 34M  \n",
      "ways_tags.csv...........................: 25M  \n",
      "San Antonio-checkpoint.ipynb............: 88K  \n",
      "San Antonio-Copy1-checkpoint.ipynb......: 84K  \n",
      "San Antonio-Copy2-checkpoint.ipynb......: 57K  \n",
      "San Antonio-Copy3-checkpoint.ipynb......: 57K  \n",
      "schema-checkpoint.ipynb.................: 72B  \n",
      "Untitled-checkpoint.ipynb...............: 72B  \n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "from hurry.filesize import size\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "files_list = []\n",
    "for path, dirs, files in os.walk(dirpath):\n",
    "    files_list.extend([(filename, size(os.path.getsize(os.path.join(path, filename)))) \n",
    "                       for filename in files])\n",
    "\n",
    "for filename, size in files_list:\n",
    "    print '{:.<40s}: {:5s}'.format(filename,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The queries below show that there are 1,244,193 nodes and 144,603 ways in the SQL table.  These amounts tie to count tag functon that I used prior to importing the data set into the SQL table.  This query is a check to help ensure that we have uploaded all the data from the csv file correctly to the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1244193,)]\n"
     ]
    }
   ],
   "source": [
    "sqlite_file\n",
    "\n",
    "# Connecting to the database file\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "QUERY1 = '''SELECT COUNT(*) \n",
    "FROM nodes'''\n",
    "\n",
    "cur.execute(QUERY1)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144603,)]\n"
     ]
    }
   ],
   "source": [
    "QUERY2 = '''SELECT COUNT(*) \n",
    "FROM ways'''\n",
    "\n",
    "cur.execute(QUERY2)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users is 828."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(828,)]\n"
     ]
    }
   ],
   "source": [
    "QUERY3 = '''SELECT COUNT(DISTINCT(e.uid))\n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e\n",
    "'''\n",
    "\n",
    "cur.execute(QUERY3)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below shows the number of top 10 amenties in the area.  Places of worship, schools, and restaurants round out the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'place_of_worship', 1061), (u'school', 361), (u'restaurant', 231), (u'fast_food', 183), (u'parking_entrance', 120), (u'bench', 94), (u'pharmacy', 78), (u'toilets', 69), (u'fuel', 59), (u'grave_yard', 59)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY4 = '''SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;'''\n",
    "\n",
    "cur.execute(QUERY4)\n",
    "result = cur.fetchall()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that burger restaurants are the most prevalent in San Antonio.  I would have guessed Mexican restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'burger', 34), (u'sandwich', 33), (u'mexican', 16), (u'chicken', 11), (u'pizza', 8), (u'chinese', 4), (u'american', 3), (u'ice_cream', 2), (u'barbecue', 1), (u'breakfast', 1)]\n"
     ]
    }
   ],
   "source": [
    "QUERY5 = '''SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='fast_food') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;'''\n",
    "\n",
    "cur.execute(QUERY5)\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'kre3d', 463460), (u'woodpeck_fixbot', 345214), (u'Bellhalla', 157122), (u'homeslice60148', 135411), (u'Vaderf', 23574), (u'TexasNHD', 14188), (u'GoldenStar365', 12513), (u'25or6to4', 11838), (u'happy5214', 11806), (u'balrog-kun', 11768), (u'peace2', 11566), (u'25or6to4_upload', 11287), (u'DaveHansenTiger', 8934), (u'kammann', 5925), (u'RichRico', 5422), (u'Tony McFalls', 4969), (u'ryanr', 4957), (u'JustAnotherVogon', 4928), (u'Chris Lawrence', 4709), (u'OneLeggedOne', 4629), (u'Rudloff', 4622), (u'ras_oscar', 4086), (u'Brian@Brea', 3302), (u'TXST-cr20', 2772), (u'Sundance', 2709), (u'dannykath', 2571), (u'alhazen', 2409), (u'zephyr', 2379), (u'Iowa Kid', 2312), (u'calfarome', 2083), (u'claysmalley', 2062), (u'Hackobo', 2025), (u'karitotp', 1957), (u'samely', 1949), (u'Jano John Akim Franke', 1921), (u'rcaito', 1914), (u'Luis36995', 1819), (u'NE2', 1797), (u'Tinsote', 1762), (u'Mitchell Thomas', 1690), (u'ediyes', 1676), (u'RoadGeek_MD99', 1657), (u'afdreher', 1657), (u'TXBuckeye', 1645), (u'freebeer', 1639), (u'Splat_', 1622), (u'David Ziff', 1548), (u'Longhorn256', 1458), (u'OxyMoeRon', 1458), (u'bconnaway', 1426), (u'yurasi', 1398), (u'TheDruid', 1384), (u'bfg9000d', 1314), (u'TreesUnknown', 1302), (u'RRoyal', 1284), (u'bdiscoe', 1284), (u'Col_D', 1274), (u'chdr', 1265), (u'jheddings', 1167), (u'user_5359', 1148), (u'Spanholz', 1137), (u'Geogast', 1132), (u'derp9', 1117), (u'mattm01', 1101), (u'andrewpmk', 1063), (u'Kyle Gates', 1061), (u'abel801', 1038), (u'Nick Mac', 996), (u'Zartbitter', 988), (u'obz476', 980), (u'RyanRoyal', 979), (u'jacobbraeutigam', 978), (u'Fabi2', 976), (u'38LKTG', 878), (u'Timothy Smith', 792), (u'Latze', 773), (u'andygol', 742), (u'ridixcr', 741), (u'FrViPofm', 733), (u'erjiang', 726), (u'animebirder', 723), (u'Sean McMains', 717), (u'Granite', 707), (u'reholl', 681), (u'marioface1989', 672), (u'Rupert Swarbrick', 664), (u'nikhilprabhakar', 638), (u'stephen-w-oneal', 629), (u'GVELAYO', 624), (u'iandees', 601), (u'ksturm2', 571), (u'mdb1', 549), (u'rolandg', 543), (u'scottyc', 542), (u'mbrucker', 534), (u'California Bear', 463), (u'Andrew Matheny', 462), (u'Dami_Tn', 449), (u'Altheo', 448), (u'lziegenhals', 443), (u'hysinth', 404), (u'PHerison', 385), (u'Lambertus', 380), (u'RubenLopez', 378), (u'MichaelSteffen', 375), (u'StellanL', 350), (u'piligab', 341), (u\"Cap'n Refsmmat\", 340), (u'maxugglan', 335), (u'thevirginian', 335), (u'SapientFool', 332), (u'srividya_c', 319), (u'ygtai', 318), (u'MartyMartPa', 317), (u'razormage', 310), (u'IanH', 297), (u'brandonrose', 291), (u'skquinn', 286), (u'robgeb', 282), (u'TorhamZed', 274), (u'Human_USB', 271), (u'Nightbreed', 270), (u'Astro King', 262), (u'NativeTexan', 256), (u'Emily Glaeser', 248), (u'sebastic', 246), (u'beweta', 244), (u'StephenSchwarz', 236), (u'oldtopos', 226), (u'jfloyd', 225), (u'maxerickson', 225), (u'jpmartin1977', 224), (u'Wolfram Sobotta', 221), (u'flyboyaces', 221), (u'tw55447', 215), (u'keinseier', 213), (u'amillar', 207), (u'ruthmaben', 204), (u'ramyaragupathy', 198), (u'River Chase', 196), (u'GoWestTravel', 193), (u'bluenovember', 181), (u'michalg0x5a', 179), (u'mvexel', 175), (u'Bicep Emoji', 172), (u'dalmond', 158), (u'tombonezz', 158), (u'Larsacus', 157), (u'moosejaw', 157), (u'Trevor Bolton', 153), (u'mash84121', 152), (u'fredjunod', 150), (u'Betza', 149), (u'docrock24', 147), (u'Amuche', 146), (u'FeralWolf', 142), (u'PlaneMad', 142), (u'pyram', 142), (u'richlv', 140), (u'allofit333', 139), (u'torapa', 137), (u'bjfarrar', 136), (u'msidoric', 136), (u'jessmo78155', 135), (u'JasonWi', 134), (u'mneko', 134), (u'sullynole', 134), (u'bushu314', 133), (u'MatthewG', 132), (u'ybp9003', 132), (u'gcjunge', 130), (u'Milo', 129), (u'jonesydesign', 129), (u'jazztunes', 126), (u'pschonmann', 126), (u'BlaseEW', 120), (u'jinalfoflia', 117), (u'techlady', 117), (u'MikeN', 109), (u'pzq243', 108), (u'45723', 107), (u'angelpasta20', 107), (u'EricTheLinguist', 105), (u'Phil Scherer', 104), (u'KristenK', 102), (u'bot-mode', 101), (u'Fa7C0N', 100), (u'AMY-jin', 99), (u'NotDrinking', 95), (u'Eckhart W\\xf6rner', 94), (u'Enock4seth', 92), (u'versed', 92), (u'hofoen', 90), (u'Constable', 89), (u'davidearl', 89), (u'tcarcur', 89), (u'MysticCrab', 88), (u'sphyg', 87), (u'kkendres', 86), (u'uboot', 84), (u'Cesarg123', 83), (u'Thomas8122', 83), (u'txst', 83), (u'Chris Repka', 82), (u'DoubleA', 82), (u'Jonathan Pa', 82), (u'southtexasmonkey33', 82), (u'khoegenauer', 79), (u'Anthonyfish46', 78), (u'theworks345', 76), (u'FTA', 73), (u'er1013', 73), (u'Redinx', 72), (u'arunkb', 72), (u'Adriene Russell', 71), (u'rtzoeller', 71), (u'Cam4rd98', 69), (u'Jerre Cope', 69), (u'TreyNTX69', 68), (u'Zachary Hudson', 67), (u'Dan Richner', 66), (u'anttiklemm', 66), (u'Harry Wood', 65), (u'mgoe', 63), (u'bavario', 62), (u'egore911', 62), (u'maggot27', 62), (u'micahcochran', 62), (u'thetableleg', 62), (u'Rub21', 61), (u'vkungys', 61), (u'willoyd', 61), (u'dtlegg', 58), (u'mwMapboy', 58), (u'stangoodman', 58), (u'totes7', 58), (u'bgeezy87', 57), (u'finity', 57), (u'scai', 56), (u'Cato_d_Ae', 55), (u'Glassman', 55), (u'AmiFritz', 53), (u'Stephen214', 53), (u'Strider007', 53), (u'houston_mapper1', 53), (u'hobbesvsboyle', 52), (u'Sarah M', 51), (u'elranchogrande', 51), (u'FvGordon', 49), (u'Ropino', 49), (u'DarkTreader', 47), (u'alanstanton', 47), (u'Tom_Holland', 46), (u'Richard Symonds', 45), (u'bbmiller', 45), (u'Chetan_Gowda', 44), (u'aio97', 44), (u'CloCkWeRX', 42), (u'Roadrunner21', 42), (u'Stoney-O', 42), (u'abellao', 42), (u'eric22', 42), (u'woodpeck_repair', 42), (u'Thea Clay', 41), (u'Tim Baggett', 41), (u'elkueb', 41), (u'mperez', 40), (u'salix01', 40), (u'tswhite', 40), (u'Alex-7', 39), (u'NEStamper', 39), (u'thetornado76', 39), (u'varmint', 39), (u'Little Brother', 38), (u'alex86450', 37), (u'caseyb', 37), (u'stucki1', 37), (u'xybot', 37), (u'gigglesmcniel', 36), (u'!i!', 35), (u'isabellekh', 35), (u'Richard Boggess', 34), (u'Tom Brown', 34), (u'rogerdog', 34), (u'posdata', 33), (u'shata', 33), (u'Bhojaraj', 32), (u'Christian Benjamin Christensen', 32), (u'Harrison379', 32), (u'bwarren', 32), (u'maxolasersquad', 32), (u'FIM', 31), (u'Henry VdP III', 31), (u'fumo7887', 31), (u'willanaya', 31), (u'Hjart', 30), (u'Howpper', 30), (u'SteveMills', 30), (u'Yunbo', 30), (u'DevinDTA', 29), (u'GerdP', 29), (u'Rovastar', 29), (u'bubbawesome', 29), (u'cceval', 29), (u'nbguy', 29), (u'CMott', 28), (u'Seth K', 28), (u'Tex24Whiskey', 28), (u'jwtorres', 28), (u'revent', 28), (u'Eric White', 27), (u'ian29', 27), (u't_woelk', 27), (u'radek-drlicka', 26), (u'willray411', 26), (u'RosasRob', 25), (u'achterberg', 25), (u'poornibadrinath', 25), (u'ManAboutCouch', 24), (u'Peter14', 24), (u'TXST1', 24), (u'david lynch', 24), (u'lyx', 24), (u'pillcrusher', 24), (u'wonderchook', 24), (u'Emily Baker', 22), (u'Rmag', 22), (u'ToeBee', 22), (u'NikhilShirahatti', 21), (u'PatriciaRichmond', 21), (u'Tisa80', 21), (u'jamesavery', 21), (u'snorlax0110', 21), (u'DZ210Legend', 20), (u'DarthWaffle', 20), (u'ELadner', 20), (u'Glen', 20), (u'JDMTX', 20), (u'boom929', 20), (u'geographyking', 20), (u'stoecker', 20), (u'tgh0831', 20), (u'Eric Fischer', 19), (u'jgrnt', 19), (u'EdHillsman', 18), (u'Johnny Rob', 18), (u'RedRaider74', 18), (u'Ryan Gentry', 18), (u'Stovall56', 18), (u'TheDude05', 18), (u'Ezellcr', 17), (u'RetiredInNH', 17), (u'Walter Schl\\xf6gl', 17), (u'choess', 17), (u'dmgroom_ct', 17), (u'gormur', 17), (u'jbond_002002', 17), (u'mg1430', 17), (u'olvagor', 17), (u'DLichti', 16), (u'Jim Salinas', 16), (u'MapMakinMeyers', 16), (u'RaquelFish09', 16), (u'elnashar77', 16), (u'lesko987', 16), (u'marscot', 16), (u'pcc322', 16), (u'qkr982', 16), (u'usernamemike', 16), (u'AM909', 15), (u'BCNorwich', 15), (u'Math1985', 15), (u'NE3', 15), (u'T_9er', 15), (u'Tamires24', 15), (u'c2r', 15), (u'derFred', 15), (u'fnolz', 15), (u'lmingle', 15), (u'mdk', 15), (u'Blackphidora', 14), (u'SomeoneElse_Revert', 14), (u'megustacomicsans', 14), (u'nvn709', 14), (u'rab', 14), (u'saikabhi', 14), (u'AaronAsAChimp', 13), (u'Claudius Henrichs', 13), (u'DigitalT', 13), (u'OSMF Redaction Account', 13), (u'gieguy', 13), (u'nammala', 13), (u'robert moritz', 13), (u'August1914', 12), (u'DennisL', 12), (u'Hundehalter', 12), (u'IknowJoseph', 12), (u'aighes', 12), (u'bluekirby0', 12), (u'nanpalmero', 12), (u'spod', 12), (u'user_599436', 12), (u'victuallers', 12), (u'Cerritus', 11), (u'HB2015', 11), (u'StackKorora', 11), (u'wambacher', 11), (u'wheelmap_visitor', 11), (u'zors1843', 11), (u'ASPhoto', 10), (u'ChrisZontine', 10), (u'Chuy0063', 10), (u'Claydo', 10), (u'D_Prado', 10), (u'KR-KRKR-KR', 10), (u'Valdizle', 10), (u'_atlas', 10), (u'bmccartney', 10), (u'hno2', 10), (u'reunify_aarti', 10), (u'souldivide', 10), (u'van Rees', 10), (u'Alberto187', 9), (u'Claumirez', 9), (u'Grant Rostig', 9), (u'Money G', 9), (u'SAmapworks', 9), (u'adjuva', 9), (u'clara', 9), (u'colindt', 9), (u'dchall8', 9), (u'hhester93', 9), (u'mueschel', 9), (u'rickmastfan67', 9), (u'sparx', 9), (u'42429', 8), (u'Davlak', 8), (u'Gene Gagnon', 8), (u'JasonWoof', 8), (u'Mark_S', 8), (u'Markbert', 8), (u'brogo', 8), (u'chollo', 8), (u'h4ck3rm1k3', 8), (u'jameswoppelt', 8), (u'jorge_o', 8), (u'kisaa', 8), (u'seav', 8), (u'wasat', 8), (u'HPTouchpad5', 7), (u'Jacob Allred', 7), (u'LeTopographeFou', 7), (u'Munchabunch', 7), (u'PabloLobo', 7), (u'TheHammer', 7), (u'UTSAquist', 7), (u'craigloftus', 7), (u'deepank', 7), (u'grouper', 7), (u'hca', 7), (u'jneptune', 7), (u'liamrocker', 7), (u'miciah1', 7), (u'pitg600', 7), (u'talkradio', 7), (u'Carl Simonson', 6), (u'Chris Bardash', 6), (u'Goblue512', 6), (u'Human BackPack', 6), (u'Mikideez', 6), (u'NayanataraM', 6), (u'bhavana naga', 6), (u'bitdba', 6), (u'emireles', 6), (u'ivansanchez', 6), (u'ormandj', 6), (u'pete404', 6), (u'sparaosm', 6), (u'wolfgang8741', 6), (u'AJoh1', 5), (u'Aaron Lidman', 5), (u'Carlovzla', 5), (u'ChrissW-R1', 5), (u'Edgarv', 5), (u'Ginnyrivera', 5), (u'Hisham E', 5), (u'Jake Davenport', 5), (u'Jamwa', 5), (u'Mongome', 5), (u'My Texas Home Resource', 5), (u'NightAuthor', 5), (u'Patrick_Asher', 5), (u'Sat', 5), (u'Sebastien Duthil', 5), (u'TheBrit', 5), (u'YannC', 5), (u'ashleyannmathew', 5), (u'cgu66', 5), (u'cirrostratus', 5), (u'dirkmunson', 5), (u'fx99', 5), (u'kjon', 5), (u'lyzidiamond', 5), (u'maggsbe', 5), (u'malajul', 5), (u'msdess', 5), (u'nmccasland', 5), (u'oini', 5), (u'robbii', 5), (u'sbook', 5), (u'sclamons', 5), (u'svillarreal521', 5), (u'timwxx', 5), (u'uiwcardinals', 5), (u'user_179600', 5), (u'Anthony Moffa', 4), (u'Baldgoon', 4), (u'Chelsey', 4), (u'David & Christine Schmitt', 4), (u'Derick Rethans', 4), (u'GuyParker', 4), (u'JeffersonOutreach', 4), (u'JoshPig', 4), (u'Manu1400', 4), (u'MilaZ', 4), (u'Polarbear', 4), (u'R0bst3r', 4), (u'Tom Chance', 4), (u'Tznischd', 4), (u'Ub3rm3nscH', 4), (u'agjr55', 4), (u'colby125', 4), (u'coleman', 4), (u'dancedavedance', 4), (u'edcjar2020', 4), (u'elehack', 4), (u'gpsradler', 4), (u'jazbo', 4), (u'jharpster', 4), (u'jry417', 4), (u'manoharuss', 4), (u'mapsinE3', 4), (u'matthieun', 4), (u'sabas88', 4), (u'sfong1963', 4), (u'shravan91', 4), (u'Aleks-Berlin', 3), (u'Alvaro da Matta', 3), (u'Artemio Meras', 3), (u'ArtiePenguin1', 3), (u'CenTex Chris', 3), (u'Crowdof5', 3), (u'Dave SATX', 3), (u'GilTAzchargd', 3), (u'HamishB', 3), (u'Heinz_V', 3), (u'Imp_GL', 3), (u'Kelly WEX', 3), (u'Koen Stokes', 3), (u'Md Alamgir', 3), (u'Pat Kohler', 3), (u'QuentinGrimaud', 3), (u'Richard Cash', 3), (u'SteveDorries', 3), (u'Teddy80', 3), (u'TheDillo', 3), (u'TomHynes', 3), (u'daleoffret', 3), (u'dchiles', 3), (u'dcp', 3), (u'derandi', 3), (u'geochrome', 3), (u'hfs', 3), (u'homeland12453', 3), (u'jeffjordan', 3), (u'jumbanho', 3), (u'mrw6060', 3), (u'odowell88', 3), (u'osm-sputnik', 3), (u'ssohaney', 3), (u'troyengel', 3), (u'txag9', 3), (u'wolfv', 3), (u'4b696d', 2), (u'517634', 2), (u'Axxom', 2), (u'Bman', 2), (u'BryanSK', 2), (u'CP7871', 2), (u'CalliBrown', 2), (u'Circularenix', 2), (u'ColinMarquardt', 2), (u'Dale E Moore', 2), (u'Daniel Neel', 2), (u'David03622', 2), (u'Dero Bike Racks', 2), (u'Geospizinae', 2), (u'Hao Nguyen 13', 2), (u'HattoriHanzo', 2), (u'Hobgoblin', 2), (u'HolgerJeromin', 2), (u'JLedet', 2), (u'Jake Strine', 2), (u'Jonathan ZHAO', 2), (u'Jothirnadh', 2), (u'JulienBalas', 2), (u'Kamikaze74', 2), (u'Lion & Rose', 2), (u'Map Man-ia', 2), (u'NateLion', 2), (u'Ohr', 2), (u'Omnific', 2), (u'OpenBrian', 2), (u'PA94', 2), (u'Paul B Powers', 2), (u'PaulRotering', 2), (u'PierZen', 2), (u'Pierre-Alain Dorange', 2), (u'Randy826', 2), (u'RichRico_labuildings', 2), (u'Rps333', 2), (u'Shang Lin Hu', 2), (u'ToffeHoff', 2), (u'Tracy Miller', 2), (u'Travis Bashir', 2), (u'Vlad', 2), (u'Worship Bassist (Aaron)', 2), (u'aarthy', 2), (u'achims311', 2), (u'bikegeek', 2), (u'breic', 2), (u'corywright', 2), (u'elbatrop', 2), (u'ericthecaveman', 2), (u'geobrando', 2), (u'habi', 2), (u'hefee', 2), (u'j3d', 2), (u'jaakkoh', 2), (u'jsf1984', 2), (u'khiita', 2), (u'lhillberg', 2), (u'mapper999', 2), (u'maximeguillaud', 2), (u'mlbrice', 2), (u'mtmail', 2), (u'n76', 2), (u'nazgul5', 2), (u'nfgusedautoparts', 2), (u'nicolas17', 2), (u'redoregon', 2), (u'riordabr', 2), (u'samlarsen1', 2), (u'samramarm', 2), (u'svance92', 2), (u'upendrakarukonda', 2), (u'user_870861', 2), (u'wmann', 2), (u'yasse1406', 2), (u'zytsef', 2), (u'1248', 1), (u'2ndchancebailb', 1), (u'AE35', 1), (u'Alamo Junction', 1), (u'Aleandporter', 1), (u'AndrewBuck', 1), (u'Ave Arboris', 1), (u'BGabriel', 1), (u'BK Tejas', 1), (u'Blobo123', 1), (u'Boerneman', 1), (u'Bryce C Nesbitt', 1), (u'Burnfreak', 1), (u'Carl S', 1), (u'Carney Inc', 1), (u'Christoph Lotz', 1), (u'DB Broker LLC', 1), (u'Data411', 1), (u'Dezzy', 1), (u'DomB5', 1), (u'Dracer', 1), (u'Drew Peterson', 1), (u'Dvon of Edzore', 1), (u'Edgar Eduardo Moreno', 1), (u'Enlightened Behavioral Health Systems', 1), (u'Gavin', 1), (u'Gutsycat', 1), (u'HJD', 1), (u'Head', 1), (u'HotelPORT', 1), (u'Hyatt Hyatt', 1), (u'Hyatt Regency San Antonio Riverwalk', 1), (u'Ixta', 1), (u'JImmy UDP Roman', 1), (u'JerryJ', 1), (u'Jojamza', 1), (u'Josef73', 1), (u'Karisa', 1), (u'LiLRunnyNick', 1), (u'Lusidd', 1), (u'MaZderMind', 1), (u'Maskulinum', 1), (u'Med', 1), (u'Mora Augustin', 1), (u'MrCranky', 1), (u'My Cook', 1), (u'Olivier Delaune', 1), (u'PaigePink', 1), (u'Paul Johnson', 1), (u'Paul Joiner', 1), (u'Peter Pain (Brandon Lee)', 1), (u'Prof Eric Cameron', 1), (u'Rabsaque', 1), (u'Red1222', 1), (u'RicoZ', 1), (u'Robert L Hughlette', 1), (u'Robert Whittaker', 1), (u'SK53', 1), (u'SP!KE', 1), (u'Sharlin', 1), (u'SophienburgTech', 1), (u'StefVIS', 1), (u'Stemby', 1), (u'SultryDread', 1), (u'Syl', 1), (u'Tellez Law Group', 1), (u'The hiker', 1), (u'TxBrum', 1), (u'TxCNC', 1), (u'Ubreakifix Selma', 1), (u'Vincent Broman', 1), (u'Vintagejhan', 1), (u'WENJIANG CHU', 1), (u'WanMil', 1), (u'agile1', 1), (u'angys', 1), (u'anprvrentals', 1), (u'blendergeek', 1), (u'championwindows', 1), (u'chicagocust', 1), (u'chicagopizzeriatx', 1), (u'chuckfu', 1), (u'ckc', 1), (u'clarceneaux', 1), (u'coop_spec', 1), (u'cvsawindow', 1), (u'dforsi', 1), (u'elocksmithsananton', 1), (u'emacsen_dwg', 1), (u'faafhny', 1), (u'ghaliadresses', 1), (u'gondoi', 1), (u'grbarsch', 1), (u'griffinlikegryphon', 1), (u'heidmol', 1), (u'hfyu', 1), (u'hopfavogl', 1), (u'jacobmartinez', 1), (u'jasonrobertsSatx', 1), (u'jgpacker', 1), (u'jman1983', 1), (u'johndoe7979', 1), (u'kay_D', 1), (u'kbomby', 1), (u'laelectronics', 1), (u'lrmahon', 1), (u'luispkw', 1), (u'lvgeek', 1), (u'manings', 1), (u'merichardson5', 1), (u'mgalisa', 1), (u'mircozorzo', 1), (u'mitchelldaygis', 1), (u'mjn', 1), (u'mn-driver', 1), (u'moonsa', 1), (u'morray', 1), (u'mostserene', 1), (u'mstriewe', 1), (u'nicknockerz', 1), (u'nicolashes', 1), (u'ninjamask', 1), (u'nmixter', 1), (u'o2Haus', 1), (u'oddboy', 1), (u'oldenburg69', 1), (u'onelinkmortgage', 1), (u'patjones', 1), (u'paulmach', 1), (u'pawelh', 1), (u'pieniazek', 1), (u'piligab_labuildings', 1), (u'r4vi', 1), (u'rackbdc13', 1), (u'raidernation97', 1), (u'reds1', 1), (u'remingtonhotels', 1), (u'robbieonsea', 1), (u'rolandgarcia1', 1), (u'rowers2', 1), (u'rumpelsocke', 1), (u'rupetho', 1), (u'rustremdi', 1), (u'ryangay', 1), (u'safamilyattorneys', 1), (u'sandro442', 1), (u'sankeyequipmentcompany', 1), (u'saspaorgtx', 1), (u'seguin-gold-silver-coins', 1), (u'stateleatherco', 1), (u'steverumizen', 1), (u'stevevitola', 1), (u'strevino04', 1), (u't-i', 1), (u'tcarobruce', 1), (u'texanhouse', 1), (u'texassounds', 1), (u'thesteady', 1), (u'thinkdifferentsa', 1), (u'tmcw', 1), (u'trigpoint', 1), (u'trinityhillsalon', 1), (u'ulfl', 1), (u'urbanuniforms2', 1), (u'vickdw', 1), (u'werner2101', 1), (u'xunilOS', 1), (u'zehpunktbarron', 1)]\n"
     ]
    }
   ],
   "source": [
    "QUERY6 = '''SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC;'''\n",
    "\n",
    "cur.execute(QUERY6)\n",
    "result_user = cur.fetchall()\n",
    "print(result_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kre3d</td>\n",
       "      <td>463460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woodpeck_fixbot</td>\n",
       "      <td>345214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bellhalla</td>\n",
       "      <td>157122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homeslice60148</td>\n",
       "      <td>135411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaderf</td>\n",
       "      <td>23574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User   Count\n",
       "0            kre3d  463460\n",
       "1  woodpeck_fixbot  345214\n",
       "2        Bellhalla  157122\n",
       "3   homeslice60148  135411\n",
       "4           Vaderf   23574"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(result_user)\n",
    "df = df.rename(columns={0: 'User', 1: 'Count'})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1677.289855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21342.918840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>463460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count\n",
       "count     828.000000\n",
       "mean     1677.289855\n",
       "std     21342.918840\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%        10.000000\n",
       "75%        79.750000\n",
       "max    463460.000000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 828 users in the San Antonio data set.  However, the data seems to be skewed by super users.  For example, the top 4 users all have over 100k contributions each and account for over 1.1M contributions.  I believe these users are skewing the data set and should be removed from any further data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kre3d</td>\n",
       "      <td>463460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woodpeck_fixbot</td>\n",
       "      <td>345214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bellhalla</td>\n",
       "      <td>157122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homeslice60148</td>\n",
       "      <td>135411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaderf</td>\n",
       "      <td>23574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User   Count\n",
       "0            kre3d  463460\n",
       "1  woodpeck_fixbot  345214\n",
       "2        Bellhalla  157122\n",
       "3   homeslice60148  135411\n",
       "4           Vaderf   23574"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(df.index[[0,1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaderf</td>\n",
       "      <td>23574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TexasNHD</td>\n",
       "      <td>14188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GoldenStar365</td>\n",
       "      <td>12513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25or6to4</td>\n",
       "      <td>11838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy5214</td>\n",
       "      <td>11806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User  Count\n",
       "4         Vaderf  23574\n",
       "5       TexasNHD  14188\n",
       "6  GoldenStar365  12513\n",
       "7       25or6to4  11838\n",
       "8      happy5214  11806"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>349.015777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1540.420883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23574.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count\n",
       "count    824.000000\n",
       "mean     349.015777\n",
       "std     1540.420883\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%       10.000000\n",
       "75%       73.750000\n",
       "max    23574.000000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean drops significantly from 1677 to 349 contributions per user just by removing the top four users from the data set.  However, there still appears to be a major drop off in user contributions with 50% of the users only making 2 contributions.  Additionally, the 75th percentile is at 74 contributions per user. Motivating the 50th and 75th percentile user base should be a next step to continually improve the accuracy of the San Antonio area.\n",
    "\n",
    "One possible way to increase involvement is to use gamification.  For example, Treehouse is a virtual training academy for learning code, app development, and business skills, used by beginners to learn valuable career skills and experienced professionals for career advancement.  Students earn badges and points as they progress thru courses which impresses potential employers.  Openstreetmap.org should team up with virtual training academies like Treehouse and integrate map updates as part of data wrangling curriculm.  Since Treehouse is free there should be a lot of opportunity for participation from new users.\n",
    "\n",
    "\n",
    "Benefits\n",
    "    1) Many available students to update map accuracy.\n",
    "    2) Utilizes successful gamification system already used at Treehouse\n",
    "\n",
    "Anticipated Issues\n",
    "    1) How long will this be sustainable?  How much work is actually needed to clean up the maps?  Is this a 1 year effort or 10?\n",
    "    2) Version control - How do you prevent overwriting of contributions by others."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
